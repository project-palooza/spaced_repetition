{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1285720 entries, 0 to 1285720\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count    Dtype         \n",
      "---  ------             --------------    -----         \n",
      " 0   p_recall           1285720 non-null  float64       \n",
      " 1   timestamp          1285720 non-null  datetime64[ns]\n",
      " 2   delta              1285720 non-null  int64         \n",
      " 3   user_id            1285720 non-null  object        \n",
      " 4   learning_language  1285720 non-null  object        \n",
      " 5   ui_language        1285720 non-null  object        \n",
      " 6   lexeme_id          1285720 non-null  object        \n",
      " 7   lexeme_string      1285720 non-null  object        \n",
      " 8   history_seen       1285720 non-null  int64         \n",
      " 9   history_correct    1285720 non-null  int64         \n",
      " 10  session_seen       1285720 non-null  int64         \n",
      " 11  session_correct    1285720 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(5), object(5)\n",
      "memory usage: 127.5+ MB\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "p = 0.1  # 10% of the lines\n",
    "# keep the header, then take only 10% of lines\n",
    "# if random from [0,1] interval is greater than 0.1 the row will be skipped\n",
    "df = pd.read_csv(\n",
    "         'learning_traces.13m.csv',\n",
    "         header=0, \n",
    "         skiprows=lambda i: i>0 and random.random() > p\n",
    ")\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'],unit='s')\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p_recall                                          1.0\n",
       "timestamp                         2013-02-28 18:28:01\n",
       "delta                                        27649635\n",
       "user_id                                          u:FO\n",
       "learning_language                                  de\n",
       "ui_language                                        en\n",
       "lexeme_id            35a54c25a2cda8127343f6a82e6f6b7d\n",
       "lexeme_string                mann/mann<n><m><sg><nom>\n",
       "history_seen                                        5\n",
       "history_correct                                     4\n",
       "session_seen                                        1\n",
       "session_correct                                     1\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before we try to learn good values for theta \n",
    "# we need to construct x\n",
    "\n",
    "# x = information a students history learning a certain word\n",
    "\n",
    "df.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (df['p_recall'] == (df['session_correct'])/(df['session_seen'])).sum() == df.shape[0]\n",
    "\n",
    "# p_recall is the ratio of session_correct/session_seen\n",
    "\n",
    "# p_recall is \"y\" \"ground truth\"\n",
    "\n",
    "# predicted_p_recall is \"y_hat\" \"prediction\"\n",
    "\n",
    "# error(p_recall,predicted_p_recall) <- we want this to be as small as possible\n",
    "\n",
    "# if we can very reliably predict p_recall, what is the value of this in real-life terms?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get parts of speech\n",
    "\n",
    "def lexeme_df(filename):\n",
    "\n",
    "    import re\n",
    "    df_single_col = pd.read_csv(filename, delimiter='\\t', header=None, names=['line'])\n",
    "\n",
    "    def split_line(line):\n",
    "        parts = re.split(r'\\s+', line, maxsplit=2)\n",
    "        if len(parts) == 3:\n",
    "            return parts\n",
    "        return [None, None, None]\n",
    "\n",
    "    df_split = df_single_col['line'].apply(split_line)\n",
    "    df = pd.DataFrame(df_split.tolist(), columns=['lexeme', 'category', 'meaning'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexeme</th>\n",
       "      <th>category</th>\n",
       "      <th>meaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa</td>\n",
       "      <td>animacy</td>\n",
       "      <td>Animate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acr</td>\n",
       "      <td>adjective</td>\n",
       "      <td>Acronym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adj</td>\n",
       "      <td>POS</td>\n",
       "      <td>Adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adv</td>\n",
       "      <td>POS</td>\n",
       "      <td>Adverb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>al</td>\n",
       "      <td>other</td>\n",
       "      <td>Other (altre)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lexeme   category        meaning\n",
       "0     aa    animacy        Animate\n",
       "1    acr  adjective        Acronym\n",
       "2    adj        POS      Adjective\n",
       "3    adv        POS         Adverb\n",
       "4     al      other  Other (altre)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexemes = lexeme_df('lexeme_reference.txt')\n",
    "lexemes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexemes['lexeme'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               n><m><sg><nom>\n",
       "1             prn><itg><m><sg>\n",
       "2          vblex><pri><p2><sg>\n",
       "3                    n><f><sg>\n",
       "4          vblex><pri><p3><pl>\n",
       "                  ...         \n",
       "1285716         n><m><pl><nom>\n",
       "1285717                   adv>\n",
       "1285718    vblex><pri><p3><sg>\n",
       "1285719          det><def><sp>\n",
       "1285720           vblex><pres>\n",
       "Name: lexeme_string, Length: 1285720, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encoding\n",
    "# dummy variables / indicator variables\n",
    "\n",
    "df.loc[0,\"lexeme_string\"]\n",
    "\n",
    "\"<det><def><nt><sg><nom>\"\n",
    "\n",
    "# det, df, nt, sg, nom + 87 more \n",
    "\n",
    "# word | det | def | nt | sg | nom | ...\n",
    "# das  |  1  | 1   | 1  | 1  |  1  | 0 ...\n",
    "\n",
    "\n",
    "\n",
    "# look for the first <, remove everything to the left\n",
    "# then remove <, >\n",
    "\n",
    "# \n",
    "\n",
    "def extract_right_of_lt(text):\n",
    "    import re\n",
    "    match = re.search(r'<(.*)', text)\n",
    "    return match.group(1) if match else ''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               n m sg nom\n",
       "1             prn itg m sg\n",
       "2          vblex pri p2 sg\n",
       "3                   n f sg\n",
       "4          vblex pri p3 pl\n",
       "                ...       \n",
       "1285716         n m pl nom\n",
       "1285717                adv\n",
       "1285718    vblex pri p3 sg\n",
       "1285719         det def sp\n",
       "1285720         vblex pres\n",
       "Name: lexeme_string, Length: 1285720, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = df['lexeme_string'].apply(extract_right_of_lt)\n",
    "words = words.str.replace(\"<\",\" \")\n",
    "words = words.str.replace(\">\",\"\")\n",
    "words = words.str.replace(\"*\",\"\")\n",
    "words = words.str.replace(\"/\",\"\")\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorized_words = vectorizer.fit_transform(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3138"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no longer optimizing this for now,\n",
    "# i want to talk about specifying the model\n",
    "# we'll return to this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should start with a really simple feature vector\n",
    "# (history_seen, history_correct)\n",
    "\n",
    "simple_df = df[['p_recall','history_seen','history_correct']]\n",
    "\n",
    "# input_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h_hat = 2**(theta*x)\n",
    "\n",
    "# we need an error function to quantify how wrong we are\n",
    "\n",
    "# (p_recall - predicted_p_recall)**2 <- error\n",
    "# predicted_p_recall = 2**(-1*(delta/predicted_half_life))\n",
    "# predicted_half_life = 2**(theta*x)\n",
    "\n",
    "\n",
    "# given\n",
    "# p_recall is given\n",
    "# delta is given\n",
    "# x is given\n",
    "\n",
    "# we don't have theta\n",
    "\n",
    "# we are going initialize theta with some random numbers\n",
    "# so then we have theta\n",
    "\n",
    "# once we have theta we can calculate the error\n",
    "# and start learning\n",
    "\n",
    "# to-do\n",
    "\n",
    "# write formulas for predicted half_life and predicted p_recall\n",
    "# write formula for loss function\n",
    "# and import an optimizer \n",
    "# run the optimizer on the loss function + our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to use pytorch\n",
    "# we are using custom loss function and our model is not one of the standard ML models, like linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpacedRepetition(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SpacedRepetition, self).__init__()\n",
    "        self.theta = nn.Linear(input_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # estimating h_hat = 2^(theta . x)\n",
    "        theta_x = self.theta(x)  # dot product of theta and x\n",
    "        h_hat = torch.pow(2, theta_x)\n",
    "        return h_hat\n",
    "\n",
    "def custom_loss(p, p_hat, h, h_hat, theta, alpha, lambda_reg):\n",
    "    loss_p = torch.mean((p_hat - p) ** 2)\n",
    "    loss_h = torch.mean((h_hat - h) ** 2)\n",
    "    reg_term = lambda_reg * torch.sum(theta ** 2)\n",
    "    total_loss = loss_p + alpha * loss_h + reg_term\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object oriented programming\n",
    "\n",
    "# python is a very flexible programming language\n",
    "\n",
    "# one thing it lets you do is define things called Classes\n",
    "\n",
    "# suppose you are a game developer\n",
    "# designing a world for your game\n",
    "# and your world has trees\n",
    "# you write a tree class\n",
    "# tree class defines what attributes trees can have\n",
    "# tree: height, color, bears_fruit, number of leaves, ...\n",
    "\n",
    "# tree_A = tree(height = 100, color = green, bears_fruit = false, number of leaves = 1800)\n",
    "\n",
    "# tree class exists\n",
    "# new class called MagicTrees\n",
    "\n",
    "# class MagicTree(Tree):\n",
    "# super(MagicTree, self).__init__()\n",
    "\n",
    "# MagicTree is called a sub-class of Tree\n",
    "# Tree is a superclass of MagicTree\n",
    "\n",
    "# linear regression is implemented as a class\n",
    "# result = smf.ols(\"y ~ x\",data=df)\n",
    "# result.summary\n",
    "# result.params\n",
    "# ....\n",
    "\n",
    "# class SpacedRepetition(nn.Module)\n",
    "# super(SpacedRepetition, self).__init__()\n",
    "\n",
    "# inheritance\n",
    "\n",
    "\n",
    "# __init__(self, input_dim) \"dunder method\" \"double underscore method\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = SpacedRepetition(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
